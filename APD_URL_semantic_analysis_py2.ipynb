{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install seaborn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6RBbUE-tvVT"
   },
   "source": [
    "# CLUE : Clustering for Mining Web URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqgEN1gruQsJ"
   },
   "source": [
    "We aim at finding a method for digging inside a data set of URLs. The main purpose is the obtention of a clustering workflow that would allow us to directly get segments of similar URLs from stream-like data with no need for manual rule creation.\n",
    "\n",
    "Part of this work began in the notebook APD_Structure-URL https://colab.research.google.com/drive/1MFrvUJTGmmvTe_WAI8HmI-QeTkzwXEix with some exploratory data analysis and application of URL transformation based on pattern tree construction rules.\n",
    "\n",
    "Work presented on the current notebook is based on work from Morichetta et al.  (2017) who developed a non-specific tool for analysing massive URL data sets using text-mining methods https://www.researchgate.net/publication/312183704_CLUE_Clustering_for_Mining_Web_URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nt93lh33wTGT"
   },
   "source": [
    "## Import URL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "dRsiFwS6tVan"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import dbscan\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.set(rc={'figure.figsize': (8,8)})\n",
    "\n",
    "df_url = pd.read_csv('URL_dataset.csv', encoding='utf8')\n",
    "df_url = df_url.loc[pd.notna(df_url['segment_name'])].drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "tGNZ3QzWx7yp",
    "outputId": "2dfd2f86-0f81-4129-ba24-4cc956d810e3"
   },
   "outputs": [],
   "source": [
    "print('Total URL: %i' %len(df_url['url']))\n",
    "print('Unique URL: %i' %df_url['url'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnoK9iKztpdw"
   },
   "source": [
    "## 1. URL-distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AN0zSvWv7h_"
   },
   "source": [
    "URL distance computation does not have real-time constriants and can be schedule when the data collection is complete, or also on demand.\n",
    "\n",
    "The concept of **distance** refers to a specific class of dissimilarity measures that aim at quantifying how much two points $x_1$ and $x_2$ are far apart in a numerical way. A dissimilarity measure must meet 3 propreties in order to be called a distance :\n",
    "\n",
    "- **positivity** : $\\forall (x_1, x_2), d(x_1, x_2) \\geq 0$ ; $d(x_1, x_2) = 0 \\iff x_1 = x_2$\n",
    "- **symmetry** : $\\forall (x_1, x_2), d(x_1, x_2) = d(x_2, x_1)$\n",
    "- **triangle inequality** : $\\forall (x_1, x_2, x_3), d(x_1, x_3) \\leq d(x_1, x_2) + d(x_2, x_3)$\n",
    "\n",
    "Let's bear in mind that in order to facilitate the clustering of URLs (which is our main goal), we want to keep distances between URLs concentrated within given ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjwFTpBOt-H4"
   },
   "source": [
    "### 1.1 Levenshtein distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZdFqLWsOTbA"
   },
   "source": [
    "The Levenshtein distance $d_{LVS}(s_1, s_2)$ assigns a unitary cost for all editing operations (insert, remove, replace). It computes an absolute distance  between pairs of strings that is **at most equal to the length of the longest string**. This has to be kept in mind as it might make the Levensthein distance inconvenient when it comes to comparing a very short URL against a very long one.\n",
    "\n",
    "The Levenshtein distance is defined as:\n",
    "\n",
    "$d_{LVS}(i,j) = \\max(i,j)$ if $\\min(i,j) = 0$\n",
    "\n",
    "$d_{LVS}(i,j) = \\min(d_{LVS}(i-1, j),~d_{LVS}(i, j-1),~d_{LVS}(i-1, j-1)+I(s_{1i}\\neq s_{2i}))$ otherwise\n",
    "\n",
    "Where $d_{LVS}(i,j)$ is the distance between the first $i$ characters of $s_1$ and the first $j$ characters of $s_2$ and $I$ is the indicator function, here equal to $0$ when $s_{1i} = s_{2j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uD-udWzq0e4q"
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    l1, l2 = len(s1), len(s2)\n",
    "\n",
    "    if s1 == s2:\n",
    "        return 0\n",
    "    elif l1 == 0:\n",
    "        return l2\n",
    "    elif l2 == 0:\n",
    "        return l1\n",
    "  \n",
    "    v0 = [None]*(l2+1)\n",
    "    v1 = [None]*(l2+1)\n",
    "    for i in range(len(v0)):\n",
    "        v0[i] = i\n",
    "    for i in range(l1):\n",
    "        v1[0] = i+1\n",
    "        for j in range(l2):\n",
    "            if s1[i] == s2[j]:\n",
    "                C = 0\n",
    "            else:\n",
    "                C = 1\n",
    "            v1[j+1] = min(v1[j]+1, v0[j+1]+1, v0[j]+C)\n",
    "        for j in range(len(v0)):\n",
    "            v0[j] = v1[j]\n",
    "        \n",
    "    return v1[l2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rj2pK59ouB74"
   },
   "source": [
    "### 1.2 Jaro distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GExMhx1a_A4"
   },
   "source": [
    "The Jaro distance $d_{JRO}(s_1, s_2)$ considers **the number and the order  of common characters between two strings**.\n",
    "\n",
    "$d_{JRO} = 1$ if $m = 0$\n",
    "\n",
    "$d_{JRO} = 1 - \\frac{1}{3}(\\frac{m}{|s_1|}+\\frac{m}{|s_2|}+\\frac{m-t}{m})$ otherwise\n",
    "\n",
    "where $m$ is the number of matching characters and $t$ is half the number of  transpositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "g6pH5eYBKkvp"
   },
   "outputs": [],
   "source": [
    "def jaro_distance(s1, s2):\n",
    "    l1, l2 = len(s1), len(s2)\n",
    "    \n",
    "    if l1 == 0 and l2 == 0:\n",
    "        return 1.\n",
    "    \n",
    "    match_distance = max(l1, l2)//2 - 1\n",
    "    s1_matches = [None]*l1\n",
    "    s2_matches = [None]*l2\n",
    "    \n",
    "    m, t = 0., 0.\n",
    "    \n",
    "    for i in range(l1):\n",
    "        start = max(0, i-match_distance)\n",
    "        end = min(i+match_distance+1, l2)\n",
    "        \n",
    "        for j in range(start, end):\n",
    "            if s2_matches[j]:\n",
    "                continue\n",
    "            if s1[i] != s2[j]:\n",
    "                continue\n",
    "            s1_matches[i] = True\n",
    "            s2_matches[j] = True\n",
    "            m += 1.\n",
    "            break\n",
    "    \n",
    "    if m == 0:\n",
    "        return 1.\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(l1):\n",
    "        if not s1_matches[k]:\n",
    "            continue\n",
    "        while not s2_matches[k]:\n",
    "            k += 1\n",
    "        if s1[i] != s2[k]:\n",
    "            t += 1.\n",
    "        k += 1\n",
    "    \n",
    "    return 1.-(1./3)*(m/l1+m/l2+(m-t/2.)/m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKUtXED6uD_Q"
   },
   "source": [
    "### 1.3 URL distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BeyQSnJsuM8n"
   },
   "source": [
    "This distance calculation $d_{URL}$ is inspired from a custom modification of the Levenshtein distance $d_{LVS_2}$. Here total number of insertions and deletions are counted and **replacement is weighted by a factor of 2**. In the end, a replacement is considered as the combination of an insertion and a deletion. **String length is also considered and results are normalised in $[0,1]$**.\n",
    "\n",
    "$d_{URL}(s_1, s_2) = 1 - \\frac{|s_1|+|s_2|-d_{LVS_2}(s_1, s_2)}{|s_1|+|s_2|}$\n",
    "\n",
    "we get $d_{URL}(s_1, s_2) = 0 \\iff s_1 = s_2$ and $d_{URL}(s_1, s_2) = 1$ if $s_1$ and $s_2$ are totally different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JtB_aNKG0mz5"
   },
   "outputs": [],
   "source": [
    "def levenshtein_distance2(s1, s2):\n",
    "    l1, l2 = len(s1), len(s2)\n",
    "\n",
    "    if s1 == s2:\n",
    "        return 0\n",
    "    elif l1 == 0:\n",
    "        return l2\n",
    "    elif l2 == 0:\n",
    "        return l1\n",
    "  \n",
    "    v0 = [None]*(l2+1)\n",
    "    v1 = [None]*(l2+1)\n",
    "    for i in range(len(v0)):\n",
    "        v0[i] = i\n",
    "    for i in range(l1):\n",
    "        v1[0] = i+1\n",
    "        for j in range(l2):\n",
    "            if s1[i] == s2[j]:\n",
    "                C = 0.\n",
    "            else:\n",
    "                C = 2.\n",
    "            v1[j+1] = min(v1[j]+1, v0[j+1]+1, v0[j]+C)\n",
    "        for j in range(len(v0)):\n",
    "            v0[j] = v1[j]\n",
    "        \n",
    "    return v1[l2]\n",
    "\n",
    "def url_distance(s1, s2):\n",
    "    l1, l2 = len(s1), len(s2)\n",
    "    \n",
    "    if s1 == s2:\n",
    "        return 0\n",
    "    elif l1 == 0:\n",
    "        return l2\n",
    "    elif l2 == 0:\n",
    "        return l1\n",
    "    else:\n",
    "        return 1. - (l1+l2-levenshtein_distance2(s1, s2))/(l1+l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "QDCziN75p17G",
    "outputId": "b52c58a0-4419-44c3-d821-977a64558cfb"
   },
   "outputs": [],
   "source": [
    "#CLUE article test example\n",
    "s1, s2 = 'google.com', '1goggle.com'\n",
    "print('dLVS(\\'{}\\', \\'{}\\') = %s'.format(s1, s2)  %np.round(levenshtein_distance(s1, s2),3))\n",
    "print('dJRO(\\'{}\\', \\'{}\\') = %s'.format(s1, s2)  %np.round(jaro_distance(s1, s2),3))\n",
    "print('dURL(\\'{}\\', \\'{}\\') = %s'.format(s1, s2)  %np.round(url_distance(s1, s2),3))\n",
    "\n",
    "#\n",
    "#dLVS('google.com', '1goggle.com') = 2\n",
    "#dJRO('google.com', '1goggle.com') = 0.094\n",
    "#dURL('google.com', '1goggle.com') = 0.143\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNRa71JcOnS0"
   },
   "source": [
    "### 1.4 Distances CDF and distance measure selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUOG5zqWZHaR"
   },
   "source": [
    "#### 1.4.1 Format URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "6zBcu8sfTbyO"
   },
   "outputs": [],
   "source": [
    "U = df_url['url'].drop_duplicates().sample(frac=0.005).tolist()\n",
    "print('Unique URL: %i' %len(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWM_JtBHeiBJ"
   },
   "source": [
    "#### 1.4.2 Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "e4gCtIiJOoNK"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#calculate distances between each pair of URLs\n",
    "lvs_matrix = np.zeros((len(U),len(U)), dtype=np.float)\n",
    "for i in range(0, len(U)):\n",
    "    for j in range(0, len(U)):\n",
    "        lvs_matrix[i,j] = np.round(levenshtein_distance(U[i],U[j]),2)\n",
    "\n",
    "#build CDF array\n",
    "to_plot_lvs = lvs_matrix.ravel()\n",
    "to_plot_lvs_sorted = np.sort(to_plot_lvs)\n",
    "p = 1.*np.arange(len(to_plot_lvs))/(len(to_plot_lvs)-1)\n",
    "\n",
    "#plot CDF\n",
    "plot = sns.lineplot(to_plot_lvs_sorted, p)\n",
    "plot.set(title='Cumulative distribution function of Levenshtein distance on the URL data set',\n",
    "         xlabel='dLVS',\n",
    "         ylabel='CDF');\n",
    "plot.set(ylim=[0, 1]);    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PYD_RDddcMmH"
   },
   "source": [
    "#### 1.4.3 Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "aJkImaHJeuyv"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#calculate distances between each pair of URLs\n",
    "jro_matrix = np.zeros((len(U),len(U)), dtype=np.float)\n",
    "for i in range(0, len(U)):\n",
    "    for j in range(0, len(U)):\n",
    "        jro_matrix[i,j] = np.round(jaro_distance(U[i],U[j]),3)\n",
    "\n",
    "#build CDF array\n",
    "to_plot_jro = jro_matrix.ravel()\n",
    "to_plot_jro_sorted = np.sort(to_plot_jro)\n",
    "p = 1.*np.arange(len(to_plot_jro))/(len(to_plot_jro)-1)\n",
    "\n",
    "#plot CDF\n",
    "plot = sns.lineplot(to_plot_jro_sorted, p)\n",
    "plot.set(title='Cumulative distribution function of Jaro distance on the URL data set',\n",
    "         xlabel='dJRO',\n",
    "         ylabel='CDF');\n",
    "plot.set(ylim=[0, 1]);       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_eVD74Meo0_"
   },
   "source": [
    "#### 1.4.4 URL distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "i3t2aXvcevWi"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#calculate distances between each pair of URLs\n",
    "url_matrix = np.zeros((len(U),len(U)), dtype=np.float)\n",
    "for i in range(0, len(U)):\n",
    "    for j in range(0, len(U)):\n",
    "        url_matrix[i,j] = np.round(url_distance(U[i],U[j]),3)\n",
    "#print(url_matrix)\n",
    "\n",
    "#build CDF array\n",
    "to_plot_url = url_matrix.ravel()\n",
    "to_plot_url_sorted = np.sort(to_plot_url)\n",
    "p = 1.*np.arange(len(to_plot_url))/(len(to_plot_url)-1)\n",
    "\n",
    "#plot CDF\n",
    "plot = sns.lineplot(to_plot_url_sorted, p)\n",
    "plot.set(title='Cumulative distribution function of URL distance on the URL data set',\n",
    "         xlabel='dURL',\n",
    "         ylabel='CDF');\n",
    "plot.set(ylim=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPBvYSQkaERW"
   },
   "source": [
    "## 2. URL clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4tO8rfVjaIvS"
   },
   "source": [
    "Here we aim at grouping together points according to the $d_{URL}$ distance function introduced above. URLs grouped in the same cluster share common features and we'll see if we can further consider that they represent a segment.\n",
    "\n",
    "Clustering is performed using **DBSCAN**, a density-based clustering method, which shows several advantages over centroid-based approaches (such as *k-means clustering*):\n",
    "- there is no need for prior knowledge of the total number of clusters\n",
    "- arbitrarily-shaped clusters can be discovered\n",
    "- outliers are considered and some may be left apart clustering as noise\n",
    "\n",
    "Illustration : let us consider a set of points in a sample space to be clustered. Let $d(x_1, x_2)$ be the distance between two points $x_1$ and $x_2$. Consider now the sphere of radius $r$ centered in $x_1$. If at least $minPoints$ are within distance $d \\leq r$ from $x_1$, then $x_1$ is classified as **core point**. The $minPoints$ are defiend as *directly reachable* from $x_1$. \n",
    "A given point $x_k$ is said to be *reachable* from $x_1$ if there exists a path $x_1, x_2, \\dots, x_k$ so that $x_{i+1}$ is directly reachable from $x_i$. The subset of reachable points from $x_1$ form a **cluster**, i.e. a **dense region**. \n",
    "Points that are not reachable from $x_1$ are **outliers**, they may form a separate cluster if they fall in a separate dense region, or remain in the noise region as outliers.\n",
    "\n",
    "Although $minPoints$ and $r$ can be tuned by the user, the critical parameter is $r$, the radius of the sphere that indeed defines the enveloppe of the cluster. A too small value of $r$ would lead to a too high number of clusters and outliers, whereas a too large value of $r$ would lead to a too small number of clusters, showing heterogeneity. Authors even warn about the fact that choice of $r$ needs a preliminary study since it can completely change clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wE6v_qpl46Iz"
   },
   "source": [
    "### 2.1 Radius $r$ sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhqIp462ewdW"
   },
   "source": [
    "We use $d_{URL}$ as the distance measure between the URLs we want to cluster. Since $d_{URL} \\in [0, 1]$ by construction, we choose to make $r$ vary within a range at first. Following we compute a sort of *grid search* over parameters $r$ and $minPoints$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Z19I3YRFofuf",
    "outputId": "1b9e2cb2-0d1a-4f4b-b80f-798ce19cf692"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "U = df_url['url'].drop_duplicates().sample(frac=0.005).tolist()\n",
    "print('Unique URL: %i\\n' %len(U))\n",
    "array_U = np.arange(len(U)).reshape(-1, 1)\n",
    "\n",
    "#calculate distances between each pair of URLs using url_distance\n",
    "url_matrix = np.zeros((len(U),len(U)), dtype=np.float)\n",
    "for i in range(0, len(U)):\n",
    "    for j in range(0, len(U)):\n",
    "        url_matrix[i,j] = np.round(url_distance(U[i],U[j]),4)\n",
    "\n",
    "clustering_results = {'r': [],\n",
    "                      'N_clusters': [],\n",
    "                      'Noise_elements': []}\n",
    "for r in [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.75]:\n",
    "    res_tmp = dbscan(url_matrix, metric='precomputed', eps=r, min_samples=8)\n",
    "    n_clusters_tmp = len(np.unique(res_tmp[1]))\n",
    "    n_noise_tmp = np.count_nonzero(res_tmp[1]==-1)\n",
    "    clustering_results['r'].append(r)\n",
    "    clustering_results['N_clusters'].append(n_clusters_tmp)\n",
    "    clustering_results['Noise_elements'].append(n_noise_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wxLBSXFObkGI"
   },
   "outputs": [],
   "source": [
    "# clust = OPTICS(min_samples=2, xi=.05, min_cluster_size=.05)\n",
    "# X = np.arange(len(U)).reshape(-1, 1)\n",
    "# clust.fit(X)\n",
    "\n",
    "# labels_a = cluster_optics_dbscan(reachability=clust.reachability_,\n",
    "#                                    core_distances=clust.core_distances_,\n",
    "#                                    ordering=clust.ordering_, eps=0.0005)\n",
    "\n",
    "# labels_b = cluster_optics_dbscan(reachability=clust.reachability_,\n",
    "#                                    core_distances=clust.core_distances_,\n",
    "#                                    ordering=clust.ordering_, eps=0.005)\n",
    "\n",
    "# space = np.arange(len(X))\n",
    "# reachability = clust.reachability_[clust.ordering_]\n",
    "# labels = clust.labels_[clust.ordering_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4eC-Ro-ZePO2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "APD-URL_semantic_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
